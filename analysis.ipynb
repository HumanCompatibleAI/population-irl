{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import gym\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pirl\n",
    "from pirl.experiments import config, experiments, plots as myplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "experiment = 'dummy-continuous-test-slow-20180423_171736-f12823ea19bd9c1321eb9b7bfbec69066ae73641'\n",
    "experiment_dir = osp.join('data', experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Value difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_value(experiment_dir, algo_pattern='(.*)', env_pattern='(.*)', algos=['.*'], dps=2):\n",
    "    fname = osp.join(experiment_dir, 'results.pkl')\n",
    "    data = pd.read_pickle(fname)\n",
    "    \n",
    "    value = myplots.extract_value(data)\n",
    "    value.columns = value.columns.str.extract(algo_pattern, expand=False)\n",
    "    envs = value.index.levels[0].str.extract(env_pattern, expand=False)\n",
    "    value.index = value.index.set_levels(envs, level=0)\n",
    "    \n",
    "    matches = []\n",
    "    mask = pd.Series(False, index=value.columns)\n",
    "    for p in algos:\n",
    "        m = value.columns.str.match(p)\n",
    "        matches += list(value.columns[m & (~mask)])\n",
    "        mask |= m\n",
    "    value = value.loc[:, matches]\n",
    "    \n",
    "    value.columns = value.columns.str.split('_').str.join(' ')  # so lines wrap\n",
    "    value = value.round(dps)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_pattern = '(.*)'\n",
    "env_pattern = '(.*)'\n",
    "plot_value(experiment_dir, algo_pattern, env_pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy rollout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expert_value(rl, env_name, discount=0.99, seed=1234, episodes=100):\n",
    "    '''Rollout a cached expert policy for episodes.\n",
    "       WARNING: This will be slow or just break if policy is not in cache!'''\n",
    "    gen_policy, _sample, compute_value = config.RL_ALGORITHMS[rl]\n",
    "    policy, value = experiments._train_policy(rl, discount, env_name, seed, None)\n",
    "    vmean, vse = value\n",
    "    print('Cached value: {:.3f} +/- {:.3f}'.format(vmean, 1.96 * vse))\n",
    "    \n",
    "    env = gym.make(env_name)\n",
    "    rmean, rse = compute_value(env, policy, discount, num_episodes=episodes)\n",
    "    print('Rollout value: {:.3f} +/- {:.3f}'.format(rmean, 1.96 * rse))\n",
    "    \n",
    "def irl_value(experiment_dir, irl_name, env_name, num_traj, discount=0.99, episodes=100):\n",
    "    _irl_algo, _reward_wrapper, compute_value = experiments.make_irl_algo(irl_name)\n",
    "    irl_dir = osp.join(experiment_dir, 'irl', irl_name)\n",
    "    if not os.path.exists(irl_dir):\n",
    "        raise FileNotFoundError(\"No result directory {}\".format(irl_dir))\n",
    "    \n",
    "    pop_fname = osp.join(irl_dir, str(num_traj), 'policies.pkl')\n",
    "    sin_fname = osp.join(irl_dir, env_name, str(num_traj), 'policy.pkl')\n",
    "    if os.path.exists(pop_fname):\n",
    "        policies = joblib.load(pop_fname)\n",
    "        print(policies.keys())\n",
    "        policy = policies[env_name]\n",
    "    elif os.path.exists(sin_fname):\n",
    "        policy = joblib.load(sin_fname)\n",
    "    else:\n",
    "        raise FileNotFoundError(\"Neither {} or {} exists\".format(pop_fname, sin_fname))\n",
    "    \n",
    "    env = gym.make(env_name)\n",
    "    mean, se = compute_value(env, policy, discount, num_episodes=episodes)\n",
    "    print('Rollout value: {} +/- {}'.format(mean, 1.96 * se))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_value('ppo_cts', 'Reacher-v2', episodes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irl_value(experiment_dir, 'airl', 'Reacher-v2', 1000, episodes=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing rewards (gridworld only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (4,4)\n",
    "irl_algo = 'mces'\n",
    "figs = myplots.gridworld_heatmap(data['rewards'][irl_algo], shape)\n",
    "for fig in figs:\n",
    "    display(fig[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to disk\n",
    "out_dir = './figs/some-experiment'\n",
    "for k, v in data['reward'].items():\n",
    "    pirl.experiments.plots.save_figs(pirl.experiments.plots.gridworld_heatmap(v, (4,4)), os.path.join(out_dir, k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss curve (PPO only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppo_progress(results_dir):\n",
    "    path = osp.join(results_dir, 'progress.csv')\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.set_index('serial_timesteps')\n",
    "    return df\n",
    "\n",
    "def expert_ppo_progress(experiment_dir, env_name, rl_name):\n",
    "    results_dir = osp.join(experiment_dir, 'expert', env_name, rl_name)\n",
    "    return ppo_progress(results_dir)\n",
    "\n",
    "df = expert_ppo_progress(experiment_dir, 'Reacher-v2', 'ppo_cts')\n",
    "df['eprewmean'].plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
